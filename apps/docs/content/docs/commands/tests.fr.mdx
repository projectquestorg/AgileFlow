---
title: "/setup-tests"
description: Mettre en place une infrastructure de tests automatisés
---

# /setup-tests

Détectez automatiquement votre type de projet et démarrez une infrastructure de test complète avec l'installation du framework, la configuration, des exemples de tests et l'intégration CI.

## Démarrage rapide

```bash
/agileflow:setup-tests FRAMEWORK=auto COVERAGE=yes
```

## But

Cette commande crée une base de tests professionnels en :
- Détection automatique du langage et du framework de votre projet
- Installation des dépendances du framework de test appropriées
- Création de fichiers de configuration de test
- Génération d'exemples de tests unitaires, d'intégration et E2E
- Ajout de scripts de test à votre configuration de build
- Intégration des tests dans le pipeline CI/CD
- Création de la documentation de tests et des meilleures pratiques
- Exécution de tests pour vérifier que la configuration fonctionne

## Paramètres

| Parameter | Required | Default | Description |
|-----------|----------|---------|-------------|
| `FRAMEWORK` | No | `auto` | `auto`, `jest`, `mocha`, `pytest`, `rspec`, `go-test`, `cargo-test` |
| `COVERAGE` | No | `yes` | Enable coverage reporting: `yes` or `no` |
| `E2E` | No | `no` | Include E2E tests: `yes` or `no` |

## Exemples

### Détection et configuration automatiques

```bash
/agileflow:setup-tests
```

Détecte Node.js/Python/Ruby/Go/Rust et installe le framework approprié.

### Cadre spécifique à la force

```bash
/agileflow:setup-tests FRAMEWORK=jest COVERAGE=yes
```

Utilise Jest pour les tests avec la couverture activée.

### Inclure les tests E2E

```bash
/agileflow:setup-tests E2E=yes
```

Configure les tests unitaires, d'intégration ET de bout en bout (Playwright pour les applications Web).

### Projet Python

```bash
/agileflow:setup-tests FRAMEWORK=pytest
```

Installe pytest avec couverture et crée des exemples de tests.

## Détection de projet

La commande détecte automatiquement votre pile technologique :

| Tech Stack | Framework | Detected By |
|-----------|-----------|-------------|
| Node.js | Jest | package.json |
| Node.js (older) | Mocha | package.json |
| Python | pytest | requirements.txt, pyproject.toml |
| Ruby | RSpec | Gemfile |
| Go | go test | go.mod |
| Rust | cargo test | Cargo.toml |
| Java | JUnit | pom.xml, build.gradle |
| .NET | xUnit/NUnit | *.csproj |

## Fichiers de sortie

La commande crée une configuration de test complète :

### Fichiers de configuration

**Jest** (`jest.config.js`) :
```javascript
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  coverageDirectory: 'coverage',
  collectCoverageFrom: [
    'src/**/*.{js,ts}',
    '!src/**/*.d.ts',
  ],
  coverageThreshold: {
    global: {
      branches: 70,
      functions: 70,
      lines: 70,
      statements: 70
    }
  }
};
```

**pytest** (`pytest.ini`) :
```ini
[pytest]
testpaths = tests
python_files = test_*.py *_test.py
addopts = --cov=src --cov-report=html --cov-report=term
```

**RSpec** (`.rspec`) :
```text
--format documentation
--require spec_helper
```

### Structure du répertoire

Crée des répertoires de tests organisés :

<FileTree>
  <Folder name="tests">
    <Folder name="unit" />
    <Folder name="integration" />
    <Folder name="e2e" />
    <Folder name="fixtures" />
    <Folder name="helpers" />
  </Folder>
</FileTree>

### Exemples de tests

**Unit Test** (`tests/unit/example.test.ts`) :
```typescript
describe('Example Test Suite', () => {
  it('should pass this example test', () => {
    expect(true).toBe(true);
  });

  it('should test basic math', () => {
    expect(2 + 2).toBe(4);
  });
});
```

**Component Test** (`tests/components/Button.test.tsx`) :
```typescript
import { render, screen, fireEvent } from '@testing-library/react';
import Button from '@/components/Button';

describe('Button Component', () => {
  it('renders with text', () => {
    render(<Button>Click Me</Button>);
    expect(screen.getByText('Click Me')).toBeInTheDocument();
  });

  it('calls onClick when clicked', () => {
    const handleClick = jest.fn();
    render(<Button onClick={handleClick}>Click</Button>);
    fireEvent.click(screen.getByText('Click'));
    expect(handleClick).toHaveBeenCalledTimes(1);
  });
});
```

**Integration Test** (`tests/integration/api.test.ts`) :
```typescript
import request from 'supertest';
import app from '@/app';

describe('API Integration Tests', () => {
  it('GET / should return 200', async () => {
    const response = await request(app).get('/');
    expect(response.status).toBe(200);
  });

  it('POST /api/users should create user', async () => {
    const response = await request(app)
      .post('/api/users')
      .send({ name: 'Test User', email: 'test@example.com' });
    expect(response.status).toBe(201);
    expect(response.body).toHaveProperty('id');
  });
});
```

**E2E Test** (`tests/e2e/login.spec.ts`) :
```typescript
import { test, expect } from '@playwright/test';

test('user can log in', async ({ page }) => {
  await page.goto('http://localhost:3000/login');
  await page.fill('input[name="email"]', 'test@example.com');
  await page.fill('input[name="password"]', 'password123');
  await page.click('button[type="submit"]');
  await expect(page).toHaveURL('http://localhost:3000/dashboard');
});
```

### Scripts NPM

Mis à jour `package.json`:
```json
{
  "scripts": {
    "test": "jest",
    "test:watch": "jest --watch",
    "test:coverage": "jest --coverage",
    "test:unit": "jest tests/unit",
    "test:integration": "jest tests/integration",
    "test:e2e": "playwright test"
  }
}
```

### Intégration CI

Ajoute une tâche de test à `.github/workflows/ci.yml`:
```yaml
test:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4

    - name: Setup Node
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run tests
      run: npm test -- --coverage

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage/lcov.info
```

### Documentation

Crée `docs/02-practices/testing.md`:
```markdown
# Testing Guide

## Running Tests

npm test              # Run all tests
npm run test:watch    # Watch mode
npm run test:coverage # With coverage report
npm run test:unit     # Unit tests only

## Writing Tests

### Unit Tests
- Test individual functions/classes in isolation
- Mock external dependencies
- Fast (\<10ms per test)

### Integration Tests
- Test multiple components together
- Use real dependencies when possible
- Medium speed (\<100ms per test)

### E2E Tests
- Test full user flows
- Run against real app
- Slow (seconds per test)

## Coverage Requirements

- Minimum 70% coverage (enforced in CI)
- New code should be 90%+ covered
- Critical paths require 100% coverage

## Best Practices

- Use descriptive test names (Given/When/Then)
- One assertion per test when possible
- Avoid test interdependence
- Use factories/fixtures for test data
```

## Types de tests

### Tests unitaires
**What**: Tester des fonctions/classes individuelles de manière isolée
**Speed**: Rapide (< 10 ms chacun)
**Mocking**: Oui, fausses dépendances
**Coverage**: La plupart du code devrait avoir des tests unitaires

Exemple : Testez une fonction utilitaire qui calcule l'âge de l'utilisateur.

### Tests d'intégration
**What**: tester plusieurs composants fonctionnant ensemble
**Speed**: Moyen (< 100 ms chacun)
**Mocking**: Minimal, utiliser des composants réels
**Coverage**: Workflows critiques et routes API

Exemple : testez que le flux d'authentification fonctionne de bout en bout avec la base de données.

### Tests E2E (facultatif)
**What**: Tester des flux utilisateur complets dans une application réelle
**Speed**: Lent (secondes par test)
**Mocking**: Aucun, application réelle
**Coverage**: Parcours utilisateurs critiques uniquement

Exemple : inscription de l'utilisateur → connexion → affichage du flux du tableau de bord.

## Seuils de couverture

Seuils par défaut (raisonnables, pas perfectionnistes) :
- **Branches**: 70% - Tous les chemins de décision couverts
- **Functions**: 70% - Toutes fonctions appelées
- **Lines**: 70% - Toutes les lignes exécutées
- **Statements**: 70% - Toutes les déclarations sont exécutées

**Why not 100%?**
- Une couverture à 100 % ne garantit pas une exactitude à 100 %
- Certains codes sont difficiles à tester (UI, cas extrêmes)
- Rendements décroissants après 70-80 %
- Concentrez-vous plutôt sur les chemins critiques

## Exécution de tests

### Pendant le développement
```bash
npm run test:watch
```
Exécute automatiquement des tests lorsque les fichiers changent.

### Avant de s'engager
```bash
npm test
npm run test:coverage
```
Suite de tests complète avec vérification de couverture.

### En CI
S'exécute automatiquement à chaque poussée :
```bash
npm test -- --coverage --ci
```

## Flux de travail

La configuration suit ces étapes :

1. **Detect Language/Runtime**
   - Recherche package.json, Gemfile, go.mod, etc.
   - Détermine le cadre approprié

2. **Check Existing Setup**
   - Analyse les répertoires de tests (test/, tests/, __tests__/)
   - Vérifie les fichiers de configuration de test
   - Détecte la configuration CI

3. **Show Setup Plan**
   ```
   Will install:
   - jest, @types/jest, ts-jest
   - @testing-library/react

   Will create:
   - jest.config.js
   - tests/ directory structure
   - Example tests

   Will update:
   - package.json (test scripts)
   - .github/workflows/ci.yml (test job)

   Proceed? (YES/NO)
   ```

4. **Install Dependencies**
   - installation npm, installation pip, installation groupée, etc.

5. **Create Configuration**
   - Fichiers de configuration spécifiques au framework

6. **Generate Examples**
   - Exemple de test unitaire
   - Exemple de test d'intégration
   - Exemple de test E2E (si demandé)

7. **Update Scripts and CI**
   - Ajouter des commandes de test
   - Intégration au flux de travail existant

8. **Run Tests**
   - Vérifier que la configuration fonctionne
   - Afficher le rapport de couverture

9. **Create Documentation**
   - Guide de test
   - Meilleures pratiques
   - Attentes de couverture

## Prochaines étapes

Une fois la configuration terminée :

1. **Run Tests Locally**
   ```bash
   npm test
   npm run test:watch
   ```

2. **Write First Tests**
   - Commencez par les tests unitaires pour les utilitaires
   - Ajouter des tests d'intégration pour les API
   - Ajoutez ultérieurement des tests E2E pour les flux critiques

3. **Enable Coverage Checks**
   - CI nécessite une couverture minimale
   - Fusion bloquée en cas de baisse de couverture

4. **Monitor Coverage Trends**
   - Utilisez codecov.io ou similaire
   - Suivre la couverture au fil du temps
   - Célébrez les améliorations

## Meilleures pratiques

1. **Write Tests Early** - TDD ou fonctionnalités parallèles
2. **Keep Tests Fast** - Simulation d'opérations lentes
3. **Use Descriptive Names** - Le nom du test explique ce qu'il teste
4. **One Assert Per Test** - Lorsque cela est possible, rend les échecs clairs
5. **DRY in Tests** - Utiliser les montages, les usines, le montage/démontage
6. **Test Behavior** - Pas de détails de mise en œuvre
7. **Avoid Flakiness** - Pas de problèmes de timing, de pannes aléatoires
8. **Clean Up** - Réinitialiser l'état entre les tests

## Commandes associées

- [`/ci-setup`](/commands/ci) - Mettre en place le workflow CI/CD
- [`/setup-déploiement`](/commands/deploy) - Configurer le déploiement
- [`/paquets`](/commands/packages) - Gérer les dépendances des tests
