---
title: Datenbank
description: Datenbankspezialist für Schemadesign, Migrationen, Abfrageoptimierung und Datenmodellierung.
---
# Datenbankagent

Der Datenbankagent (AG-DATABASE) ist Ihr Datenbankspezialist für den Entwurf effizienter Schemata, das Schreiben sicherer Migrationen, die Optimierung von Abfragen und die Verwaltung der Datenintegrität. Es stellt sicher, dass Ihre Datenbankschicht leistungsfähig, wartbar und zuverlässig ist.

## Fähigkeiten

- Entwerfen Sie effiziente Datenbankschemata (Tabellen, Beziehungen, Einschränkungen)
- Schreiben Sie umkehrbare Migrationsskripte mit Rollback-Strategien
- Langsame Abfragen optimieren (fehlende Indizes identifizieren, Abfragestruktur verbessern)
- Verhindern Sie N+1-Abfrageprobleme und SELECT *-Anti-Patterns
- Stellen Sie die Datenintegrität durch Einschränkungen und Validierung sicher
- Überprüfen Sie Abfragen von der AG-API auf Leistungsprobleme
- Dokumentieren Sie Datenmodelle und Beziehungen zu Architektur-ADRs
- Koordinierung mit AG-API bezüglich ORM-Nutzung und Abfragemustern
- Überwachen Sie die Leistung und den Zustand der Datenbank

## Wann zu verwenden

Verwenden Sie den Datenbankagenten, wenn:

- Sie müssen eine neue Tabellen- oder Beziehungsstruktur entwerfen
– Sie müssen ein Migrationsskript für Schemaänderungen erstellen
- Sie bemerken sgeringe Abfragen oder Leistungsprobleme
- Sie möchten eine komplexe Datenbankabfrage optimieren
- Sie müssen Indizes zu häufig abgefragten Spalten hinzufügen
- Sie entwerfen Datenmodelle für eine neue Funktion
- Sie möchten N+1-Abfragemuster verhindern, bevor sie auftreten
- Sie müssen die Datenschichtarbeit mit der AG-API koordinieren

## Wie es funktioniert

1. **Kontextladen**: Agent liest Fachwissen, CLAUDE.md und Datenbankkonfiguration
2. **Story Review**: Agent identifiziert Datenanforderungen und Beziehungen
3. **Planmodus**: Agent entwirft Schema und Migrationsstrategie (für Änderungen mit hohem Risiko)
4. **Schema-Design**: Der Agent erstellt Entitätsbeziehungsdiagramme und normalisiert Daten
5. **Migrationserstellung**: Der Agent schreibt umkehrbare Auf-/Ab-Skripte mit Tests
6. **Koordination**: Der Agent teilt das Schema mit der AG-API und überprüft deren Abfragen
7. **Optimierung**: Der Agent fügt Indizes hinzu und verhindert N+1-Abfragemuster
8. **Verifizierung**: Der Agent führt Tests durch, um sicherzustellen, dass alles erfolgreich ist
9. **Dokumentation**: Agent aktualisiert status.json und appbeendet Busnachrichten

## Beispiel

```bash
# Via /babysit (recommended)
/agileflow:babysit
> "I need to design the database schema for users and posts"
```

Der Datenbankagent wird Folgendes tun:
1. Fragen Sie nach Datenbeziehungen (ein Benutzer für viele Beiträge?)
2. Entwerfen Sie ein normalisiertes Schema:
   - `users` Tabelle: ID, E-Mail, Benutzername, Passwort-Hash, erstelltes_at, aktualisiertes_at
   - `posts` Tabelle: ID, Benutzer-ID, Titel, Inhalt, erstelltes_at, aktualisiertes_at
   - Fremdschlüsseleinschränkung: posts.user_id → users.id
3. Planindizes: idx_users_email (für die Anmeldung), idx_posts_user_id (für Abfragen)
4. Erstellen Sie ein Migrationsskript mit Auf-/Ab-Vorgängen
5. Koordinieren Sie ORM-Modelle und -Abfragen mit der AG-API
6. Testen Sie das Migrations-Rollback vor Abschluss

Oder direkt spawnen:

```text
Task(
  description: "Optimize slow user profile query",
  prompt: "Query is taking 2+ seconds. Need to analyze and add missing indexes.",
  subagent_type: "agileflow-database"
)
```

## Schlüsselverhalten

- **Niemals Änderungen ohne Migrationen vornehmen**: Alle Schemaänderungen erfordern umkehrbare Migrationsskripte
- **Planmodus für risikoreiche Änderungen**: Verwendet immer den Planmodus, um Schema-/Migrationsstrategien zu entwerfen
- **Reversible Migrationen**: Jede „Up“-Migration hat eine entsprechende „Down“-Migration für ein Rollback
- **Abfrageoptimierung**: Analysiert Abfragenfür N+1-Probleme, fehlende Indizes, SELECT * Anti-Patterns
- **Namenskonventionen**: Tabellen im Plural in Kleinbuchstaben (Benutzer, Beiträge), Spalten Snake_Case (Benutzer-ID, erstelltes_at)
- **Erforderliche Spalten**: Jede Tabelle hat eine ID, erstellte_at, aktualisierte_at (und gelöschte_at für vorläufige Löschvorgänge)
- **Koordination mit AG-API**: Überprüft ihre Abfragen und ORM-Nutzung; schlägt Optimierungen vor
- **Session Harness-Integration**: Überprüft den Teststatus vor dem Start und erfordert das Bestehen von Tests vor der Überprüfung
- **Proaktive Dokumentation**: Erstellt ADRs für wichtige Schemaentscheidungen
- **Kontexterhaltung**: Verwendet „compact_context“ (Priorität: hoch), um den Fokus bei langen Gesprächen beizubehalten und Schemaentscheidungen sowie die Verfolgung der Leistungsoptimierung durch Kontextkomprimierung beizubehalten

## Kompakte Kontextkonfiguration

Der Datenbankagent verwendet Compact_Context mit **hoher Priorität**, um sicherzustellen, dass Schemadesign- und Optimierungsentscheidungen erhalten bleiben:

```yaml
compact_context:
  priority: high
  preserve_rules:
    - "LOAD EXPERTISE FIRST: Always read packages/cli/src/core/experts/database/expertise.yaml"
    - "NEVER CHANGE SCHEMA WITHOUT MIGRATION: All changes require reversible up/down scripts"
    - "PLAN MODE FOR HIGH-RISK CHANGES: Design schema/migration strategy before implementation"
    - "VERIFY TEST BASELINE: Check test_status before starting new work"
    - "REQUIRED COLUMNS: Every table needs id, created_at, updated_at"
    - "COORDINATION WITH AG-API: Review their queries and ORM patterns"
  state_fields:
    - current_story
    - schema_changes_planned
    - migration_strategy
    - api_query_reviews
    - test_status_baseline
```

Dadurch werden datenbankkritische Regeln (Migrationsanforderungen, Schemanamen) sichergestelltg-Konventionen, erforderliche Spalten) und der aktuelle Status (welche Schemaänderungen geplant sind, welche API-Abfragen überprüft werden müssen) bleiben durch Kontextkomprimierung im Fokus.

## Werkzeuge verfügbar

Dieser Agent hat Zugriff auf: Lesen, Schreiben, Bearbeiten, Bash, Glob, Grep

## Schema-Designprinzipien

**Normalisierung**: Reduzieren Sie die Datenredundanz und verbessern Sie gleichzeitig die Datenintegrität

- Minimieren Sie doppelte Daten
- Eine Quelle der Wahrheit pro Feld
- Denormalisieren Sie nur, wenn die Leistungsanforderungen dies rechtfertigen (dokumentieren Sie, warum)

**Namenskonventionen**:

- Tabellen: Kleinbuchstaben, Plural (Benutzer, Produkte, Bestellungen)
- Spalten: Kleinbuchstaben, Snake_case (Vorname, erstellt_at)
- Fremdschlüssel: Tabellen-ID-Format (Benutzer-ID, Produkt-ID)
- Indizes: idx_table_column-Format (idx_users_email)

**Erforderliche Spalten**:

- `id`: Primärschlüssel (UUID oder automatische Inkrementierung)
- `created_at`: Wann der Datensatz erstellt wurde
- `updated_at`: Wann der Datensatz zuletzt geändert wurde
- `deleted_at`: Zeitstempel für vorläufiges Löschen (bei Verwendung von vorläufigem Löschen)

**Beziehungen**:

- Eins-zu-viele: Fremdschlüssel in vielen Tabellen
- Many-to-many: Junction-Tabelle mit zwei Fremdschlüsseln
- Eins-zu-eins: Fremdschlüssel mit Eindeutigkeitsbeschränkung

## Abfrageoptimierungsmuster

**Langsame Abfragen identifizieren**:

```sql
-- Enable query logging for queries > 100ms
-- Use database explain plan
EXPLAIN ANALYZE SELECT ...
```

**Abfragen optimieren**:

- Fügen Sie Indizes für häufig abgefragte Spalten hinzu (WHERE, JOIN, ORDER BY)
- Verwenden Sie EXPLAIN PLAN, um die Indexnutzung zu überprüfen
- Batch-Abfragen (mehrere Datensätze in einer einzigen Abfrage laden)
- Verwenden Sie CTEs/Fensterfunktionen für komplexe Aggregationen

**Häufige Probleme**:

```sql
-- BAD: N+1 problem
SELECT * FROM users;
-- Loop: SELECT * FROM posts WHERE user_id = $1;

-- GOOD: Single query with JOIN
SELECT users.*, posts.*
FROM users
LEFT JOIN posts ON users.id = posts.user_id;

-- BAD: Missing index
SELECT * FROM users WHERE email = $1;

-- GOOD: Add index on email
CREATE INDEX idx_users_email ON users(email);
```

## Best Practices für die Migration

**Sichere Migrationen**:

1. Neue Spalten als Nullable hinzufügen (kann nach und nach aufgefüllt werden)
2. Erstellen Sie Indizes, bevor Sie alte Spalten löschen
3. Testen Sie den Rollback-Plan vor der Bereitstellung
4. Sichern Sie, bevor Sie eine destruktive Migration ausführen
5. Führen Sie das Wartungsfenster aus, wenn Auswirkungen auf die Produktion möglich sind

**Umkehrbare Migrationen**:

- Jede „Aufwärts“-Migration hat eine entsprechende „Abwärts“-Migration
- Down-Migration vor der Bereitstellung getestet
- Beispiel: Spalte hinzufügen (oben) / Spalte löschen (unten)

## Koordination mit AG-API

**Schema DesZündphase**:

- AG-API beschreibt Datenanforderungen
- AG-DATABASE entwirft Schema
- Gemeinsam nach Optimierungsmöglichkeiten suchen

**Implementierungsphase**:

- AG-DATABASE erstellt Migrationsskript
- AG-API implementiert ORM-Modelle
- Koordinieren Sie die Beziehungsbelastung (eifrig vs. faul)

**Abfrageoptimierungsphase**:

- AG-API entwickelt Abfrage
- AG-DATABASE-Bewertungen für N+1 und Optimierung
- Fügen Sie nach Bedarf Indizes hinzu

## Schlüsseldateien

- **Expertise**: `packages/cli/src/core/experts/database/expertise.yaml` (Agentenspeicher)
- **Workflow**: `packages/cli/src/core/experts/database/workflow.md` (Plan → Erstellen → Selbstverbesserung)
- **Status**: `docs/09-agents/status.json` (Story-Tracking)
- **Bus**: `docs/09-agents/bus/log.jsonl` (Koordinationsnachrichten)
- **CLAUDE.md**: Datenbanktyp und ORM-Informationen
- **Recherche**: `docs/10-research/` (auf Schemaentwurfsmuster prüfen)
- **ADRs**: `docs/03-decisions/` (Entscheidungen zur Datenbankarchitektur)

## Workflow-Schritte

1. **Expertise laden**: Lesen Sie Expertise.yaml, um Schemawissen zu laden
2. **Review Story**: Identifizieren Sie Datenanforderungen und Beziehungen
3. **Planmodus aktivieren**: DEntwerfen Sie ein Schema, eine Migrationsstrategie und analysieren Sie die Auswirkungen
4. **Schema erstellen**: Definieren Sie Tabellen, Spalten, Einschränkungen und Beziehungen
5. **Migration erstellen**: Umkehrbare Auf-/Ab-Skripte schreiben
6. **Aktualisierungsstatus**: Als „in Bearbeitung“ markieren
7. **Busnachricht anhängen**: Mit AG-API koordinieren
8. **Migration testen**: Hoch- und Herunterfahren testen
9. **Optimieren**: Fügen Sie Indizes basierend auf Abfragemustern hinzu
10. **Überprüfen**: Führen Sie Tests durch, um sicherzustellen, dass die Baseline erfolgreich ist
11. **In-Review markieren**: Status nur aktualisieren, wenn test_status==bestanden
12. **Selbstverbesserung**: Führen Sie self-improve.md nach Abschluss aus

## Qualitätscheckliste

Vor dem Markieren in der Rezension:

- [ ] Schema folgt Namenskonventionen
- [ ] Alle erforderlichen Spalten vorhanden (id, erstellt_at, aktualisiert_at)
- [ ] Beziehungen richtig definiert (Fremdschlüssel, Einschränkungen)
- [ ] Migrationen sind reversibel
- [ ] Getestete Migrationen (auf und ab)
- [ ] Indizes für häufig abgefragte Spalten
- [ ] Keine N+1-Abfragemuster erwartet
- [ ] Datenintegritätsbeschränkungen durchgesetzt
- [ ] Kommentare erklären komplexes dEntscheidungen
- [ ] Backup- und Wiederherstellungsverfahren dokumentiert
- [ ] Teststatus: bestanden (überprüft über /agileflow:verify)

## Verwandte Agenten

- [`api`](/agents/api) – Implementiert ORM-Modelle und Abfragen basierend auf Schema
- [`mentor`](/agents/mentor) – Orchestriert die Datenbankarbeit als Teil der Funktionsimplementierung
- [`ci`](/agents/ci) – Richtet Testdatenbanken und Migrationstestinfrastruktur ein