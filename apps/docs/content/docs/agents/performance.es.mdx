---
title: Actuación
description: Especialista en rendimiento para optimización, creación de perfiles, evaluación comparativa, escalabilidad y funciones críticas para el rendimiento.
---
# Agente de rendimiento

El agente de rendimiento (AG-PERFORMANCE) es un especialista en optimización del rendimiento que identifica cuellos de botella, optimiza las rutas críticas y garantiza que las aplicaciones cumplan los objetivos de rendimiento. Este agente se centra en la optimización de la medición primero, no en conjeturas prematuras.

## Capacidades

- **Perfiles de rendimiento**: identifique cuellos de botella reales con herramientas de creación de perfiles
- **Creación de puntos de referencia**: Mida el rendimiento antes y después de las optimizaciones
- **Optimización de la base de datos**: elimine consultas N+1, agregue índices, optimice consultas
- **Estrategias de almacenamiento en caché**: implementar almacenamiento en caché en memoria, Redis, CDN y HTTP
- **Optimización de interfaz**: reducción del tamaño del paquete, división de código, carga diferida
- **Optimización API**: Reduzca los tiempos de respuesta, elimine operaciones costosas
- **Pruebas de carga**: prueba los límites de escalabilidad y encuentra puntos de ruptura
- **Monitoreo de rendimiento**: configure alertas para regresiones de rendimiento
- **Análisis de escalabilidad**: comprenda cómo el sistema escala con la carga
- **Documentaciónn**: cree ADR para compensar el rendimiento

## Cuándo utilizar

Utilice el Performance Agent cuando:

- Los tiempos de respuesta son lentos y necesitan optimización.
- Las consultas a la base de datos son lentas o hay N+1 problemas.
- El tamaño del paquete frontal es grande
- Necesidad de probar los límites de escalabilidad.
- El uso de memoria es alto o está creciendo
- Los puntos finales de API superan los objetivos de rendimiento
- Necesidad de implementar estrategias de almacenamiento en caché
- Establecer líneas base de desempeño.
- Creación de seguimiento y alertas del rendimiento.
- Necesidad de documentar las decisiones de desempeño.

## Cómo funciona

1. **Carga de conocimientos**: el agente lee los objetivos de experiencia y rendimiento
2. **Análisis**: el agente revisa la historia para determinar las implicaciones en el rendimiento.
3. **Perfiles**: el agente mide el rendimiento actual con las herramientas adecuadas
4. **Identificación de cuellos de botella**: el agente descubre dónde se gasta realmente el tiempo
5. **Diseño de optimización**: el agente planifica múltiples enfoques de optimización
6. **Implementación**: El agente implementa la optimización con mediciones.
7. **Benchmarking**: el agente verifica la mejoracumple con el objetivo
8. **Documentación**: el agente crea ADR que documenta las compensaciones
9. **Monitoreo**: el agente configura alertas para regresiones de rendimiento

## Ejemplo

```bash
# Via babysit - optimize slow API endpoint
/agileflow:babysit
> "The user list API endpoint is taking 5 seconds. It needs to be <200ms."

# Agent output:
# Performance Analysis: GET /api/users
#
# Current Performance: 5.2 seconds
# Target Performance: <200ms
#
# Profiling Results:
# ├── Database query: 4.8s (92% of time)
# │   └── N+1 problem: Fetching user details in loop
# ├── JSON serialization: 0.3s (6%)
# └── Network overhead: 0.1s (2%)
#
# Optimization Strategy:
# 1. Fix N+1: Use JOIN instead of loop (estimated: 4.8s → 0.2s)
# 2. Add database index on users.created_at
# 3. Implement caching with 5 minute TTL
#
# Estimated Result: <200ms after optimizations
# Correctness: All tests will still pass
# Trade-offs: Slight memory overhead for cache
#
# Status: Ready for implementation
```

## Comportamientos clave

- **Medir primero**: código de perfil para encontrar cuellos de botella reales (no adivine)
- **Evaluación comparativa antes/después**: medir siempre la mejora
- **Sin optimización prematura**: no optimice el código poco utilizado
- **La corrección es lo primero**: nunca sacrifiques la corrección por el rendimiento.
- **Documentar compensaciones**: registrar por qué se tomaron decisiones
- **Verificar bajo carga**: Pruebe el rendimiento bajo una carga realista

## Herramientas disponibles

- Leer, escribir, editar (operaciones de archivos)
- Bash (ejecutar perfiles/pruebas de carga)
- Glob (buscar código lento)
- Grep (búsqueda de problemas de rendimiento)

## Métricas de rendimiento

**Métricas clave**:
- **Tiempo de respuesta (latencia)**: ¿Cuánto tiempo lleva la operación?
- **Rendimiento**: ¿Cuántas operaciones por segundo?
- **Uso de recursos**: CPU, memoria, disco, red
- **Escalabilidad**: ¿Cómo escala el rendimiento con la carga?

**PAGObjetivos de rendimiento** (ajustar por contexto):
- Puntos finales API: menos de 200 ms de promedio, menos de 500 ms p95
- Carga de la página frontal: menos de 2 segundos para la primera pintura, menos de 5 segundos para carga completa
- Consultas a bases de datos: menos de 10 ms de media, menos de 100 ms p95
- Memoria: Estable, sin fugas, crecimiento predecible

## Herramientas de creación de perfiles

**JavaScript/Node.js**:
- Chrome DevTools: perfilador de rendimiento integrado
- Perfilador de Node.js: `node --prof`
- clinic.js: herramienta de creación de perfiles profesionales
- cañón automático: prueba de carga HTTP
- Gráficos de llamas: visualiza el tiempo dedicado a cada función.

**Python**:
- cProfile: perfilado de CPU
- Memory_profiler: análisis de uso de memoria
- py-spy: perfilador de muestreo estadístico

**Base de datos**:
- EXPLICAR ANALIZAR: Plan de consulta y tiempo de ejecución.
- Registro de consultas lento: captura consultas por encima del umbral
- Monitoreo: seguimiento del recuento de consultas, tiempo y uso de recursos.

**Frontal**:
- Chrome DevTools: pestañas Rendimiento, Red
- Faro: Auditoría de desempeño
- Web Vitals: Métricas principales (LCP, FID, CLS)

## Cuellos de botella y soluciones comunes

| Cuello de botella | Causa| Solución |
|------------|-------|----------|
| Base de datos | Consultas N+1, índices faltantes, no optimizados | Utilice JOIN, agregue índices, desnormalice |
| Respuesta API | Puntos finales lentos, llamadas externas | Almacenar en caché, optimizar consultas, paralelizar |
| Representación frontal | Reflujos, repintados, grandes paquetes | División de código, carga diferida, compresión |
| Memoria | Pérdidas de memoria, grandes estructuras de datos | Corregir fugas, paginar grandes conjuntos de datos |
| CPU | Algoritmos caros, trabajo innecesario | Optimización de algoritmos, paralelización |

## Técnicas de optimización

**Optimización de base de datos**:
```sql
-- Bad: N+1 queries (1 for users, N for details)
SELECT * FROM users;
for each user:
  SELECT * FROM user_details WHERE user_id = user.id;

-- Good: Single JOIN query
SELECT u.*, ud.* FROM users u
JOIN user_details ud ON u.id = ud.user_id;
```

**Estrategias de almacenamiento en caché**:
- **Caché en memoria**: rápido pero de tamaño limitado (Redis)
- **Caché CDN**: activos estáticos en ubicaciones de borde
- **Caché HTTP**: caché del navegador con ETag, última modificación
- **Caché de base de datos**: caché de resultados de consultas

**Optimización de interfaz**:
```javascript
// Code splitting: Load only needed code
import { lazy, Suspense } from 'react';
const HeavyComponent = lazy(() => import('./HeavyComponent'));

// Lazy loading: Load images on demand
<img loading="lazy" src="image.jpg" alt="...">

// Tree shaking: Remove unused code
import { usedFunction } from 'library'; // Only usedFunction included
```

## Prueba de carga

**Escenarios de prueba de carga**:
- **Aumento**: aumente gradualmente la carga para encontrar el punto de ruptura
- **Sostenida**: Carga constante a lo largo del tiempo- **Pico**: aumento repentino de la carga
- **Prueba de remojo**: carga sostenida durante un período prolongado

**Métricas a capturar**:
- Distribución del tiempo de respuesta (avg, p50, p95, p99)
- Rendimiento (solicitudes/segundo)
- Tasa de error (% de solicitudes fallidas)
- Uso de recursos (CPU, memoria, red)

## Análisis de escalabilidad

Sistema de prueba bajo carga creciente:

```text
Load Test Results:
├── 10 users: 150ms avg, 0% errors ✅
├── 100 users: 180ms avg, 0% errors ✅
├── 1000 users: 500ms avg, 2% errors ⚠️
├── 5000 users: 5s avg, 15% errors ❌
│
└── Bottleneck: Database can't handle 5000 concurrent connections
    Solution: Connection pooling, read replicas, caching
```

## Integración del arnés de sesión

Performance Agent se integra con Session Harness:

```text
Pre-Implementation:
├── Baseline performance measured
├── Bottleneck identified with data
└── Optimization plan reviewed

Post-Implementation:
├── Run /agileflow:verify (tests pass)
├── Benchmark improvement (meets target)
└── Verify correctness (tests still pass)
```

## Lista de verificación de calidad

Antes de completar el trabajo de marcado:

- [ ] Rendimiento actual medido y documentado
- [ ] Cuello de botella identificado con datos de elaboración de perfiles
- [] Causa raíz entendida
- [] Estrategia de optimización documentada
- [ ] Antes/después de las mediciones tomadas
- [ ] La mejora cumple con el objetivo de rendimiento
- [ ] Corrección verificada (las pruebas aún pasan)
- [ ] Compensaciones documentadas
- [ ] Monitoreo/alertas implementadas
- [] Métricas de rendimiento agregadas a la documentación.

## Modo de plan (requerido para la optimización)

La optimización del rendimiento requiere medición-primera planificación:

| Situación | Acción |
|-----------|----------------|
| "Hazlo más rápido" (vago) | → EnterPlanMode: ¡Perfil primero! |
| Operación lenta conocida | → EnterPlanMode: Optimización del diseño |
| Se necesita almacenamiento en caché | → EnterPlanMode: Invalidación del plan |
| Optimización de consultas | → EnterPlanMode: Medir antes/después |
| Problema con el tamaño del paquete | → EnterPlanMode: Analizar dependencias |

**Flujo de trabajo del modo de planificación**:
1. Perfilar el desempeño actual
2. Identificar el cuello de botella real
3. Optimización del diseño con puntos de referencia.
4. Estrategia de verificación del plan
5. Obtenga aprobación
6. Implementar, medir, verificar

## Agentes relacionados

- [`database`](/agents/database) - Optimización de consultas e índices
- [`api`](/agents/api) - Optimización del tiempo de respuesta de API
- [`ui`](/agents/ui) - Rendimiento del frontend y división de código
- [`devops`](/agents/devops) - Rendimiento de la infraestructura, escalamiento
- [`testing`](/agents/testing) - Automatización de pruebas de rendimiento

## Coordinación

La actuación Acaballero coordenadas con:

- **AG-DATABASE**: Identifica consultas lentas, revisa índices
- **AG-API**: rendimiento del punto final del perfil
- **AG-UI**: analiza los cuellos de botella del frontend
- **AG-DEVOPS**: Monitoreo de solicitudes, escalamiento de coordenadas
- **Equipo de seguimiento**: configurar alertas de rendimiento

## Comandos de barra diagonal

- `/agileflow:research:ask TOPIC=...` - Técnicas de optimización de la investigación
- `/agileflow:ai-code-review` - Código de revisión para problemas de rendimiento
- `/agileflow:adr-new` - Documentar decisiones de desempeño
- `/agileflow:tech-debt` - Deuda de desempeño del documento
- `/agileflow:impact-analysis` - Analizar el impacto en el rendimiento
- `/agileflow:status STORY=... STATUS=...` - Actualizar el estado de la historia

## Principios de desempeño

- **Mida, no adivine**: la elaboración de perfiles revela obstáculos reales
- **La optimización prematura es mala**: Optimice donde importa
- **Objetivo 80/20**: solucionar problemas que afectan el 80% del impacto
- **Optimizar primero lo peor**: abordar primero el mayor cuello de botella
- **Verificar con carga**: prueba en condiciones de carga realistas
- **Monitorear siempre**: configurar alertas para regresiones