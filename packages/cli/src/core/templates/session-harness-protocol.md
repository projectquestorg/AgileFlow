SESSION HARNESS & VERIFICATION PROTOCOL (v2.25.0+)

**CRITICAL**: Session Harness System prevents agents from breaking functionality, claiming work is done when tests fail, or losing context between sessions.

**PRE-IMPLEMENTATION VERIFICATION**

Before starting work on ANY story:

1. **Check Session Harness**:
   - Look for `docs/00-meta/environment.json`
   - If exists → Session harness is active
   - If missing → Suggest `/agileflow:session:init` to user

2. **Test Baseline Check**:
   - Read `test_status` from story in `docs/09-agents/status.json`
   - If `"passing"` → Proceed with implementation
   - If `"failing"` → STOP. Cannot start new work with failing baseline
   - If `"not_run"` → Run `/agileflow:verify` first to establish baseline
   - If `"skipped"` → Check why tests are skipped, document override decision

3. **Environment Verification** (if session harness active):
   - Run `/agileflow:session:resume` to verify environment and load context
   - Check for regressions (tests were passing, now failing)
   - If regression detected → Fix before proceeding with new story

**DURING IMPLEMENTATION**

1. **Incremental Testing**:
   - Run tests frequently during development (not just at end)
   - Fix test failures immediately (don't accumulate debt)
   - Use `/agileflow:verify US-XXXX` to check specific story tests

2. **Real-time Status Updates**:
   - Update `test_status` in status.json as tests are written/fixed
   - Append bus messages when tests pass milestone checkpoints

**POST-IMPLEMENTATION VERIFICATION**

After completing ANY changes:

1. **Run Full Test Suite**:
   - Execute `/agileflow:verify US-XXXX` to run tests for the story
   - Check exit code (0 = success required for completion)
   - Review test output for warnings or flaky tests

2. **Update Test Status**:
   - `/agileflow:verify` automatically updates `test_status` in status.json
   - Verify the update was successful
   - Expected: `test_status: "passing"` with test results metadata

3. **Regression Check**:
   - Compare test results to baseline (initial test status)
   - If new failures introduced → Fix before marking complete
   - If test count decreased → Investigate deleted tests

4. **Story Completion Requirements**:
   - Story can ONLY be marked `"in-review"` if `test_status: "passing"`
   - If tests failing → Story remains `"in-progress"` until fixed
   - No exceptions unless documented override (see below)

**OVERRIDE PROTOCOL** (Use with extreme caution)

If tests are failing but you need to proceed:

1. **Document Override Decision**:
   - Append bus message with full explanation:
   ```jsonl
   {"ts":"2025-12-06T14:00:00Z","from":"{AGENT_ID}","type":"warning","story":"US-0040","text":"Override: Marking in-review with 1 failing test. Reason: Test requires external service mock, tracked in US-0099."}
   ```

2. **Update Story Dev Agent Record**:
   - Add note to "Issues Encountered" section explaining override
   - Link to tracking issue for the failing test
   - Document risk and mitigation plan

3. **Create Follow-up Story**:
   - If test failure is real but out of scope → Create new story
   - Link dependency in status.json
   - Notify user of the override and follow-up story

**BASELINE MANAGEMENT**

After completing major milestones (epic complete, sprint end):

1. **Establish Baseline**:
   - Suggest `/agileflow:baseline "Epic EP-XXXX complete"` to user
   - Requires: All tests passing, git working tree clean
   - Creates git tag + metadata for reset point

2. **Baseline Benefits**:
   - Known-good state to reset to if needed
   - Regression detection reference point
   - Deployment readiness checkpoint
   - Sprint/epic completion marker

**INTEGRATION WITH WORKFLOW**

The verification protocol integrates into the standard workflow:

1. **Before creating feature branch**: Run pre-implementation verification
2. **Before marking in-review**: Run post-implementation verification
3. **After merge**: Verify baseline is still passing

**ERROR HANDLING**

If `/agileflow:verify` fails:
- Read error output carefully
- Check if test command is configured in `docs/00-meta/environment.json`
- Verify test dependencies are installed
- If project has no tests → Suggest `/agileflow:session:init` to set up testing
- If tests are misconfigured → Coordinate with AG-CI

**SESSION RESUME PROTOCOL**

When resuming work after context loss:

1. **Run Resume Command**: `/agileflow:session:resume` loads context automatically
2. **Check Session State**: Review `docs/09-agents/session-state.json`
3. **Verify Test Status**: Ensure no regressions occurred
4. **Load Previous Insights**: Check Dev Agent Record from previous stories

**KEY PRINCIPLES**

- **Tests are the contract**: Passing tests = feature works as specified
- **Fail fast**: Catch regressions immediately, not at PR review
- **Context preservation**: Session harness maintains progress across context windows
- **Transparency**: Document all override decisions fully
- **Accountability**: test_status field creates audit trail
